{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion Validation\n",
    "\n",
    "This notebook validates the data ingestion process by:\n",
    "- Loading data from DuckDB\n",
    "- Checking row counts per table\n",
    "- Verifying date ranges\n",
    "- Checking for missing values\n",
    "- Displaying sample records\n",
    "- Basic statistics (min/max dates, counts by month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set visualization defaults\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Connect to DuckDB\n",
    "db_path = Path('../data/nyc_mobility.duckdb')\n",
    "conn = duckdb.connect(str(db_path))\n",
    "\n",
    "print(f\"Connected to DuckDB at: {db_path}\")\n",
    "print(f\"Database exists: {db_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Available Tables\n",
    "\n",
    "First, let's see what tables were created by DLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all tables\n",
    "tables_df = conn.execute(\"\"\"\n",
    "    SELECT table_schema, table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'raw_data'\n",
    "    ORDER BY table_name\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Available tables in raw_data schema:\")\n",
    "print(tables_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Row Counts Per Table\n",
    "\n",
    "Check how many records were loaded into each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row counts for each table\n",
    "row_counts = {}\n",
    "\n",
    "# Yellow Taxi\n",
    "try:\n",
    "    count = conn.execute(\"SELECT COUNT(*) FROM raw_data.yellow_taxi\").fetchone()[0]\n",
    "    row_counts['Yellow Taxi'] = f\"{count:,}\"\n",
    "except:\n",
    "    row_counts['Yellow Taxi'] = \"Table not found\"\n",
    "\n",
    "# FHV Taxi\n",
    "try:\n",
    "    count = conn.execute(\"SELECT COUNT(*) FROM raw_data.fhv_taxi\").fetchone()[0]\n",
    "    row_counts['FHV Taxi'] = f\"{count:,}\"\n",
    "except:\n",
    "    row_counts['FHV Taxi'] = \"Table not found\"\n",
    "\n",
    "# CitiBike\n",
    "try:\n",
    "    count = conn.execute(\"SELECT COUNT(*) FROM raw_data.trips\").fetchone()[0]\n",
    "    row_counts['CitiBike Trips'] = f\"{count:,}\"\n",
    "except:\n",
    "    row_counts['CitiBike Trips'] = \"Table not found\"\n",
    "\n",
    "# Weather\n",
    "try:\n",
    "    count = conn.execute(\"SELECT COUNT(*) FROM raw_data.hourly_weather\").fetchone()[0]\n",
    "    row_counts['Hourly Weather'] = f\"{count:,}\"\n",
    "except:\n",
    "    row_counts['Hourly Weather'] = \"Table not found\"\n",
    "\n",
    "print(\"\\nRow Counts:\")\n",
    "for table, count in row_counts.items():\n",
    "    print(f\"  {table}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Yellow Taxi Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Yellow Taxi schema\n",
    "yellow_schema = conn.execute(\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'raw_data' AND table_name = 'yellow_taxi'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Yellow Taxi Schema:\")\n",
    "print(yellow_schema)\n",
    "\n",
    "# Sample records\n",
    "print(\"\\nSample Yellow Taxi Records:\")\n",
    "yellow_sample = conn.execute(\"SELECT * FROM raw_data.yellow_taxi LIMIT 5\").df()\n",
    "display(yellow_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range and statistics\n",
    "yellow_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        MIN(tpep_pickup_datetime) as min_date,\n",
    "        MAX(tpep_pickup_datetime) as max_date,\n",
    "        COUNT(*) as total_trips,\n",
    "        AVG(trip_distance) as avg_distance,\n",
    "        AVG(total_amount) as avg_fare\n",
    "    FROM raw_data.yellow_taxi\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Yellow Taxi Statistics:\")\n",
    "display(yellow_stats)\n",
    "\n",
    "# Monthly breakdown\n",
    "yellow_monthly = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(YEAR FROM tpep_pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM tpep_pickup_datetime) as month,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.yellow_taxi\n",
    "    GROUP BY year, month\n",
    "    ORDER BY year, month\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nYellow Taxi Monthly Breakdown:\")\n",
    "display(yellow_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FHV Taxi Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check FHV schema\n",
    "fhv_schema = conn.execute(\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'raw_data' AND table_name = 'fhv_taxi'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"FHV Taxi Schema:\")\n",
    "print(fhv_schema)\n",
    "\n",
    "# Sample records\n",
    "print(\"\\nSample FHV Records:\")\n",
    "fhv_sample = conn.execute(\"SELECT * FROM raw_data.fhv_taxi LIMIT 5\").df()\n",
    "display(fhv_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range and statistics\n",
    "fhv_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        MIN(pickup_datetime) as min_date,\n",
    "        MAX(pickup_datetime) as max_date,\n",
    "        COUNT(*) as total_trips\n",
    "    FROM raw_data.fhv_taxi\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"FHV Taxi Statistics:\")\n",
    "display(fhv_stats)\n",
    "\n",
    "# Monthly breakdown\n",
    "fhv_monthly = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(YEAR FROM pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM pickup_datetime) as month,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.fhv_taxi\n",
    "    GROUP BY year, month\n",
    "    ORDER BY year, month\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nFHV Taxi Monthly Breakdown:\")\n",
    "display(fhv_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CitiBike Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CitiBike schema\n",
    "citibike_schema = conn.execute(\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'raw_data' AND table_name = 'trips'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"CitiBike Schema:\")\n",
    "print(citibike_schema)\n",
    "\n",
    "# Sample records\n",
    "print(\"\\nSample CitiBike Records:\")\n",
    "citibike_sample = conn.execute(\"SELECT * FROM raw_data.trips LIMIT 5\").df()\n",
    "display(citibike_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range and statistics (note: CitiBike column names vary by year)\n",
    "# Try common column names for start time\n",
    "try:\n",
    "    citibike_stats = conn.execute(\"\"\"\n",
    "        SELECT \n",
    "            MIN(started_at) as min_date,\n",
    "            MAX(started_at) as max_date,\n",
    "            COUNT(*) as total_trips\n",
    "        FROM raw_data.trips\n",
    "    \"\"\").df()\n",
    "    date_col = 'started_at'\n",
    "except:\n",
    "    try:\n",
    "        citibike_stats = conn.execute(\"\"\"\n",
    "            SELECT \n",
    "                MIN(starttime) as min_date,\n",
    "                MAX(starttime) as max_date,\n",
    "                COUNT(*) as total_trips\n",
    "            FROM raw_data.trips\n",
    "        \"\"\").df()\n",
    "        date_col = 'starttime'\n",
    "    except:\n",
    "        print(\"Unable to determine date column\")\n",
    "        citibike_stats = None\n",
    "        date_col = None\n",
    "\n",
    "if citibike_stats is not None:\n",
    "    print(\"CitiBike Statistics:\")\n",
    "    display(citibike_stats)\n",
    "    \n",
    "    # Monthly breakdown\n",
    "    citibike_monthly = conn.execute(f\"\"\"\n",
    "        SELECT \n",
    "            EXTRACT(YEAR FROM {date_col}) as year,\n",
    "            EXTRACT(MONTH FROM {date_col}) as month,\n",
    "            COUNT(*) as trip_count\n",
    "        FROM raw_data.trips\n",
    "        GROUP BY year, month\n",
    "        ORDER BY year, month\n",
    "    \"\"\").df()\n",
    "    \n",
    "    print(\"\\nCitiBike Monthly Breakdown:\")\n",
    "    display(citibike_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Weather Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Weather schema\n",
    "weather_schema = conn.execute(\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'raw_data' AND table_name = 'hourly_weather'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Weather Schema:\")\n",
    "print(weather_schema)\n",
    "\n",
    "# Sample records\n",
    "print(\"\\nSample Weather Records:\")\n",
    "weather_sample = conn.execute(\"SELECT * FROM raw_data.hourly_weather LIMIT 5\").df()\n",
    "display(weather_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range and statistics\n",
    "weather_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        MIN(timestamp) as min_date,\n",
    "        MAX(timestamp) as max_date,\n",
    "        COUNT(*) as total_records,\n",
    "        AVG(temp) as avg_temp_celsius,\n",
    "        AVG(humidity) as avg_humidity,\n",
    "        AVG(wind_speed) as avg_wind_speed\n",
    "    FROM raw_data.hourly_weather\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Weather Statistics:\")\n",
    "display(weather_stats)\n",
    "\n",
    "# Daily breakdown\n",
    "weather_daily = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        DATE(timestamp) as date,\n",
    "        COUNT(*) as hourly_records,\n",
    "        AVG(temp) as avg_temp,\n",
    "        MIN(temp) as min_temp,\n",
    "        MAX(temp) as max_temp\n",
    "    FROM raw_data.hourly_weather\n",
    "    GROUP BY date\n",
    "    ORDER BY date\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nWeather Daily Breakdown (first 10 days):\")\n",
    "display(weather_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DLT Metadata Tables\n",
    "\n",
    "Check DLT's metadata tables to see load information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DLT loads\n",
    "try:\n",
    "    dlt_loads = conn.execute(\"\"\"\n",
    "        SELECT * FROM raw_data._dlt_loads \n",
    "        ORDER BY inserted_at DESC \n",
    "        LIMIT 10\n",
    "    \"\"\").df()\n",
    "    \n",
    "    print(\"Recent DLT Loads:\")\n",
    "    display(dlt_loads)\n",
    "except:\n",
    "    print(\"DLT metadata table not found - data may not have been loaded yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Completeness Summary\n",
    "\n",
    "Expected data for Q4 2023 (Oct-Dec):\n",
    "- **Yellow Taxi**: ~3M trips (Oct-Dec 2023)\n",
    "- **FHV**: ~15M trips (Oct-Dec 2023)\n",
    "- **CitiBike**: ~1.5M trips (Oct-Dec 2023)\n",
    "- **Weather**: 2,208 hourly records (92 days × 24 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA INGESTION VALIDATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for table, count in row_counts.items():\n",
    "    print(f\"  ✓ {table}: {count} records\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Next Steps:\")\n",
    "print(\"  1. Review data quality in 02_data_quality_assessment.ipynb\")\n",
    "print(\"  2. Perform exploratory analysis in 03_exploratory_analysis.ipynb\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()\n",
    "print(\"\\nConnection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
