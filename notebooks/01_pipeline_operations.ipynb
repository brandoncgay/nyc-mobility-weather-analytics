{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Operations - NYC Mobility & Weather Analytics\n",
    "\n",
    "This notebook walks through each step of the data pipeline, allowing you to:\n",
    "- Run the complete pipeline or individual stages\n",
    "- Validate data quality at each step\n",
    "- Troubleshoot issues\n",
    "- Monitor execution and performance\n",
    "\n",
    "## Pipeline Architecture\n",
    "\n",
    "```\n",
    "DLT Ingestion (Bronze)\n",
    "    ‚Üì\n",
    "dbt Transformation (Silver)\n",
    "    ‚Üì\n",
    "Great Expectations (Gold)\n",
    "```\n",
    "\n",
    "**Total Processing:** ~12.5M records transformed through 12 dbt models with 108 tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup & Environment Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Set project root\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Verify key directories exist\n",
    "dirs_to_check = ['src/ingestion', 'dbt', 'great_expectations', 'orchestration', 'data']\n",
    "for dir_path in dirs_to_check:\n",
    "    full_path = PROJECT_ROOT / dir_path\n",
    "    status = \"‚úÖ\" if full_path.exists() else \"‚ùå\"\n",
    "    print(f\"{status} {dir_path}\")\n",
    "\n",
    "# Check if database exists\n",
    "DB_PATH = PROJECT_ROOT / \"data\" / \"nyc_mobility.duckdb\"\n",
    "db_exists = DB_PATH.exists()\n",
    "print(f\"\\n{'‚úÖ' if db_exists else '‚ö†Ô∏è'} Database: {DB_PATH}\")\n",
    "if db_exists:\n",
    "    print(f\"   Size: {DB_PATH.stat().st_size / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: DLT Data Ingestion (Bronze Layer)\n",
    "\n",
    "Ingest raw data from external sources:\n",
    "- NYC TLC Yellow Taxi (~8.6M trips)\n",
    "- CitiBike System Data (~1.4M trips)\n",
    "- Open-Meteo Weather API (~1.5K hours)\n",
    "\n",
    "**Expected Duration:** 3-5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DLT ingestion pipeline\n",
    "print(\"üöÄ Starting DLT data ingestion...\\n\")\n",
    "print(\"This will download and load data from:\")\n",
    "print(\"  - NYC TLC (Yellow Taxi, FHV)\")\n",
    "print(\"  - CitiBike System Data\")\n",
    "print(\"  - Open-Meteo Weather API\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"poetry\", \"run\", \"python\", \"src/ingestion/run_pipeline.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Ingestion completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Duration: {duration:.1f} seconds\\n\")\n",
    "    # Show last 20 lines of output\n",
    "    print(\"Output (last 20 lines):\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n\".join(result.stdout.split(\"\\n\")[-20:]))\n",
    "else:\n",
    "    print(\"‚ùå Ingestion failed!\")\n",
    "    print(\"\\nError:\")\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and check raw data\n",
    "conn = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "print(\"üìä Raw Data Validation\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check each raw table\n",
    "tables = [\n",
    "    ('yellow_taxi', 8_000_000, 9_000_000),\n",
    "    ('fhv_taxi', 2_000_000, 3_000_000),\n",
    "    ('trips', 1_000_000, 2_000_000),  # CitiBike\n",
    "    ('hourly_weather', 1_400, 1_500),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for table, min_expected, max_expected in tables:\n",
    "    try:\n",
    "        count = conn.execute(f\"SELECT COUNT(*) FROM raw_data.{table}\").fetchone()[0]\n",
    "        passed = min_expected <= count <= max_expected\n",
    "        status = \"‚úÖ\" if passed else \"‚ö†Ô∏è\"\n",
    "        results.append({\n",
    "            'Table': f\"raw_data.{table}\",\n",
    "            'Row Count': f\"{count:,}\",\n",
    "            'Expected': f\"{min_expected:,} - {max_expected:,}\",\n",
    "            'Status': status\n",
    "        })\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            'Table': f\"raw_data.{table}\",\n",
    "            'Row Count': 'ERROR',\n",
    "            'Expected': f\"{min_expected:,} - {max_expected:,}\",\n",
    "            'Status': '‚ùå'\n",
    "        })\n",
    "\n",
    "df_validation = pd.DataFrame(results)\n",
    "display(df_validation)\n",
    "\n",
    "all_passed = all(r['Status'] == '‚úÖ' for r in results)\n",
    "print(f\"\\n{'‚úÖ All checks passed!' if all_passed else '‚ö†Ô∏è Some checks failed!'}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: dbt Transformation (Silver Layer)\n",
    "\n",
    "Transform raw data through:\n",
    "- **Staging** (4 models): Clean and standardize source data\n",
    "- **Intermediate** (2 models): Lightweight transformations\n",
    "- **Marts** (6 models): Dimension and fact tables\n",
    "- **Tests** (108 tests): Data quality validation\n",
    "\n",
    "**Expected Duration:** 1-2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dbt build (models + tests)\n",
    "print(\"üî® Starting dbt transformation...\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"poetry\", \"run\", \"dbt\", \"build\"],\n",
    "    cwd=PROJECT_ROOT / \"dbt\",\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ dbt build completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Duration: {duration:.1f} seconds\\n\")\n",
    "else:\n",
    "    print(\"‚ùå dbt build failed!\")\n",
    "\n",
    "# Show last 30 lines of output\n",
    "print(\"Output (last 30 lines):\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n\".join(result.stdout.split(\"\\n\")[-30:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate dbt Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dbt run results\n",
    "run_results_path = PROJECT_ROOT / \"dbt\" / \"target\" / \"run_results.json\"\n",
    "\n",
    "if run_results_path.exists():\n",
    "    with open(run_results_path) as f:\n",
    "        run_results = json.load(f)\n",
    "    \n",
    "    print(\"üìä dbt Execution Summary\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall stats\n",
    "    total = len(run_results['results'])\n",
    "    passed = sum(1 for r in run_results['results'] if r['status'] == 'success')\n",
    "    failed = sum(1 for r in run_results['results'] if r['status'] == 'error')\n",
    "    \n",
    "    print(f\"Total runs: {total}\")\n",
    "    print(f\"‚úÖ Passed: {passed}\")\n",
    "    print(f\"‚ùå Failed: {failed}\")\n",
    "    print(f\"Success rate: {100 * passed / total:.1f}%\\n\")\n",
    "    \n",
    "    # Break down by type\n",
    "    models = [r for r in run_results['results'] if r['unique_id'].startswith('model')]\n",
    "    tests = [r for r in run_results['results'] if r['unique_id'].startswith('test')]\n",
    "    \n",
    "    print(f\"Models: {len(models)} ({sum(1 for m in models if m['status'] == 'success')} passed)\")\n",
    "    print(f\"Tests: {len(tests)} ({sum(1 for t in tests if t['status'] == 'success')} passed)\\n\")\n",
    "    \n",
    "    # Show any failures\n",
    "    failures = [r for r in run_results['results'] if r['status'] != 'success']\n",
    "    if failures:\n",
    "        print(\"‚ö†Ô∏è Failed runs:\")\n",
    "        for fail in failures:\n",
    "            print(f\"  - {fail['unique_id']}\")\n",
    "    else:\n",
    "        print(\"‚úÖ All runs passed!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è run_results.json not found. Did dbt run successfully?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate transformed tables\n",
    "conn = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "print(\"üìä Transformed Data Validation\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check staging models\n",
    "print(\"\\nü•â Staging Models (Bronze)\")\n",
    "staging_tables = [\n",
    "    ('stg_tlc__yellow_taxi', 8_000_000, 9_000_000),\n",
    "    ('stg_tlc__fhv_taxi', 2_000_000, 3_000_000),\n",
    "    ('stg_citibike__trips', 1_000_000, 2_000_000),\n",
    "    ('stg_weather__hourly', 1_400, 1_500),\n",
    "]\n",
    "\n",
    "for table, min_exp, max_exp in staging_tables:\n",
    "    count = conn.execute(f\"SELECT COUNT(*) FROM core.{table}\").fetchone()[0]\n",
    "    status = \"‚úÖ\" if min_exp <= count <= max_exp else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {table:30} {count:>12,} rows\")\n",
    "\n",
    "# Check dimension tables\n",
    "print(\"\\nü•à Dimension Tables (Silver)\")\n",
    "dim_tables = [\n",
    "    ('dim_date', 120, 125),\n",
    "    ('dim_time', 24, 24),\n",
    "    ('dim_weather', 1_400, 1_500),\n",
    "    ('dim_location', 260, 270),\n",
    "]\n",
    "\n",
    "for table, min_exp, max_exp in dim_tables:\n",
    "    count = conn.execute(f\"SELECT COUNT(*) FROM core_core.{table}\").fetchone()[0]\n",
    "    status = \"‚úÖ\" if min_exp <= count <= max_exp else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {table:30} {count:>12,} rows\")\n",
    "\n",
    "# Check fact tables\n",
    "print(\"\\nü•á Fact Tables (Gold)\")\n",
    "fact_tables = [\n",
    "    ('fct_trips', 12_000_000, 13_000_000),\n",
    "    ('fct_hourly_mobility', 4_000, 5_000),\n",
    "]\n",
    "\n",
    "for table, min_exp, max_exp in fact_tables:\n",
    "    count = conn.execute(f\"SELECT COUNT(*) FROM core_core.{table}\").fetchone()[0]\n",
    "    status = \"‚úÖ\" if min_exp <= count <= max_exp else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {table:30} {count:>12,} rows\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Great Expectations Validation (Gold Layer)\n",
    "\n",
    "Run comprehensive data quality checks:\n",
    "- **10 validation suites**\n",
    "- **56 individual expectations**\n",
    "- Checks for completeness, consistency, and correctness\n",
    "\n",
    "**Expected Duration:** 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Great Expectations validation\n",
    "print(\"üîç Starting Great Expectations validation...\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"poetry\", \"run\", \"python\", \"great_expectations/run_validations.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Validation completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Duration: {duration:.1f} seconds\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some validations may have failed\")\n",
    "\n",
    "# Show output\n",
    "print(\"Output:\")\n",
    "print(\"=\"*60)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if validation results exist\n",
    "ge_docs_path = PROJECT_ROOT / \"great_expectations\" / \"uncommitted\" / \"data_docs\" / \"local_site\" / \"index.html\"\n",
    "\n",
    "if ge_docs_path.exists():\n",
    "    print(\"‚úÖ Data quality report available!\")\n",
    "    print(f\"\\nüìÑ Open in browser: file://{ge_docs_path}\")\n",
    "    print(\"\\nOr run: open great_expectations/uncommitted/data_docs/local_site/index.html\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Data quality report not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Overall Pipeline Validation\n",
    "\n",
    "Final checks to ensure the complete pipeline executed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive pipeline validation\n",
    "conn = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "print(\"üéØ Pipeline Health Check\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checks = []\n",
    "\n",
    "# 1. Check data freshness\n",
    "try:\n",
    "    latest_trip = conn.execute(\"\"\"\n",
    "        SELECT MAX(pickup_datetime) as latest\n",
    "        FROM core_core.fct_trips\n",
    "    \"\"\").fetchone()[0]\n",
    "    checks.append(('Data Freshness', f\"Latest trip: {latest_trip}\", '‚úÖ'))\n",
    "except Exception as e:\n",
    "    checks.append(('Data Freshness', 'ERROR', '‚ùå'))\n",
    "\n",
    "# 2. Check weather coverage\n",
    "try:\n",
    "    coverage = conn.execute(\"\"\"\n",
    "        SELECT ROUND(100.0 * SUM(CASE WHEN weather_key IS NOT NULL THEN 1 ELSE 0 END) / COUNT(*), 4)\n",
    "        FROM core_core.fct_trips\n",
    "    \"\"\").fetchone()[0]\n",
    "    checks.append(('Weather Join Coverage', f\"{coverage}%\", '‚úÖ' if coverage >= 99 else '‚ö†Ô∏è'))\n",
    "except Exception as e:\n",
    "    checks.append(('Weather Join Coverage', 'ERROR', '‚ùå'))\n",
    "\n",
    "# 3. Check for null primary keys\n",
    "try:\n",
    "    null_keys = conn.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM core_core.fct_trips WHERE trip_key IS NULL\n",
    "    \"\"\").fetchone()[0]\n",
    "    checks.append(('Null Primary Keys', f\"{null_keys} found\", '‚úÖ' if null_keys == 0 else '‚ùå'))\n",
    "except Exception as e:\n",
    "    checks.append(('Null Primary Keys', 'ERROR', '‚ùå'))\n",
    "\n",
    "# 4. Check duplicate keys\n",
    "try:\n",
    "    duplicates = conn.execute(\"\"\"\n",
    "        SELECT COUNT(*) - COUNT(DISTINCT trip_key)\n",
    "        FROM core_core.fct_trips\n",
    "    \"\"\").fetchone()[0]\n",
    "    checks.append(('Duplicate Keys', f\"{duplicates} found\", '‚úÖ' if duplicates == 0 else '‚ùå'))\n",
    "except Exception as e:\n",
    "    checks.append(('Duplicate Keys', 'ERROR', '‚ùå'))\n",
    "\n",
    "# 5. Check date dimension completeness\n",
    "try:\n",
    "    date_range = conn.execute(\"\"\"\n",
    "        SELECT \n",
    "            MIN(date_actual) as min_date,\n",
    "            MAX(date_actual) as max_date,\n",
    "            COUNT(*) as total_dates\n",
    "        FROM core_core.dim_date\n",
    "    \"\"\").fetchone()\n",
    "    checks.append(('Date Dimension', f\"{date_range[2]} dates ({date_range[0]} to {date_range[1]})\", '‚úÖ'))\n",
    "except Exception as e:\n",
    "    checks.append(('Date Dimension', 'ERROR', '‚ùå'))\n",
    "\n",
    "# Display results\n",
    "for check_name, result, status in checks:\n",
    "    print(f\"{status} {check_name:25} {result}\")\n",
    "\n",
    "all_passed = all(c[2] == '‚úÖ' for c in checks)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"{'‚úÖ Pipeline health check PASSED!' if all_passed else '‚ö†Ô∏è Some checks failed'}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Pipeline Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overall pipeline stats\n",
    "conn = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "print(\"üìà Pipeline Performance Summary\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Total records processed\n",
    "stats = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        (SELECT COUNT(*) FROM raw_data.yellow_taxi) as raw_yellow,\n",
    "        (SELECT COUNT(*) FROM raw_data.fhv_taxi) as raw_fhv,\n",
    "        (SELECT COUNT(*) FROM raw_data.trips) as raw_citibike,\n",
    "        (SELECT COUNT(*) FROM core.stg_tlc__yellow_taxi) as stg_yellow,\n",
    "        (SELECT COUNT(*) FROM core.stg_tlc__fhv_taxi) as stg_fhv,\n",
    "        (SELECT COUNT(*) FROM core.stg_citibike__trips) as stg_citibike,\n",
    "        (SELECT COUNT(*) FROM core_core.fct_trips) as fact_trips\n",
    "\"\"\").fetchone()\n",
    "\n",
    "total_raw = stats[0] + stats[1] + stats[2]\n",
    "total_staging = stats[3] + stats[4] + stats[5]\n",
    "total_fact = stats[6]\n",
    "\n",
    "print(f\"Raw Records Ingested:     {total_raw:>15,}\")\n",
    "print(f\"Staging Records:          {total_staging:>15,}\")\n",
    "print(f\"Fact Table Records:       {total_fact:>15,}\")\n",
    "print(f\"\\nData Retention Rate:      {100 * total_fact / total_raw:>14.2f}%\")\n",
    "\n",
    "# Database size\n",
    "db_size_gb = DB_PATH.stat().st_size / 1024**3\n",
    "print(f\"\\nDatabase Size:            {db_size_gb:>14.2f} GB\")\n",
    "\n",
    "# dbt stats from run results\n",
    "if run_results_path.exists():\n",
    "    with open(run_results_path) as f:\n",
    "        run_results = json.load(f)\n",
    "    \n",
    "    total_time = sum(r.get('execution_time', 0) for r in run_results['results'])\n",
    "    print(f\"dbt Execution Time:       {total_time:>14.1f} seconds\")\n",
    "    print(f\"Models Built:             {len([r for r in run_results['results'] if r['unique_id'].startswith('model')]):>15}\")\n",
    "    print(f\"Tests Passed:             {len([r for r in run_results['results'] if r['unique_id'].startswith('test') and r['status'] == 'success']):>15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Pipeline metrics calculated successfully!\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dagster Integration\n",
    "\n",
    "For production usage, run the pipeline through Dagster for:\n",
    "- Visual lineage graph\n",
    "- Dependency tracking\n",
    "- Execution history\n",
    "- Asset versioning\n",
    "- Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Dagster definitions\n",
    "print(\"üîß Dagster Configuration Check\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "    from orchestration import defs\n",
    "    \n",
    "    asset_count = len(list(defs.get_all_asset_specs()))\n",
    "    job_count = len(list(defs.get_all_job_defs()))\n",
    "    \n",
    "    print(f\"‚úÖ Dagster definitions loaded successfully\\n\")\n",
    "    print(f\"Assets defined: {asset_count}\")\n",
    "    print(f\"Jobs defined: {job_count}\")\n",
    "    \n",
    "    print(\"\\nüìù Available Jobs:\")\n",
    "    for job in defs.get_all_job_defs():\n",
    "        if not job.name.startswith('__'):\n",
    "            print(f\"  - {job.name}\")\n",
    "    \n",
    "    print(\"\\nüöÄ To run via Dagster UI:\")\n",
    "    print(\"   poetry run dagster dev -w orchestration/workspace.yaml\")\n",
    "    print(\"   Then open: http://localhost:3000\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load Dagster definitions: {e}\")\n",
    "    print(\"   This is optional - pipeline can run without Dagster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Commands Reference\n",
    "\n",
    "### Via Pipeline Script\n",
    "```bash\n",
    "# Full pipeline (DLT + dbt + GE)\n",
    "./scripts/run_pipeline.sh full\n",
    "\n",
    "# Ingestion only\n",
    "./scripts/run_pipeline.sh ingestion\n",
    "\n",
    "# Quick test\n",
    "./scripts/run_pipeline.sh quick\n",
    "\n",
    "# Validation only\n",
    "./scripts/run_pipeline.sh validate\n",
    "```\n",
    "\n",
    "### Via Direct Commands\n",
    "```bash\n",
    "# DLT ingestion\n",
    "poetry run python src/ingestion/run_pipeline.py\n",
    "\n",
    "# dbt build\n",
    "cd dbt && poetry run dbt build\n",
    "\n",
    "# Great Expectations\n",
    "poetry run python great_expectations/run_validations.py\n",
    "```\n",
    "\n",
    "### Via Dagster\n",
    "```bash\n",
    "# Start Dagster UI\n",
    "poetry run dagster dev -w orchestration/workspace.yaml\n",
    "\n",
    "# Then in UI: Jobs ‚Üí full_pipeline ‚Üí Launch Run\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Database locked error:**\n",
    "```bash\n",
    "pkill -f duckdb  # Close all DuckDB connections\n",
    "```\n",
    "\n",
    "**dbt compilation error:**\n",
    "```bash\n",
    "cd dbt\n",
    "rm -rf target/ dbt_packages/\n",
    "poetry run dbt deps\n",
    "poetry run dbt compile\n",
    "```\n",
    "\n",
    "**Missing dependencies:**\n",
    "```bash\n",
    "poetry install\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
