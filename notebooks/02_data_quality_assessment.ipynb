{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Assessment\n",
    "\n",
    "This notebook assesses the quality of ingested data by:\n",
    "- Analyzing null values per column\n",
    "- Detecting outliers in key metrics\n",
    "- Examining temporal distributions\n",
    "- Reviewing geographic distributions\n",
    "- Calculating data completeness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Set visualization defaults\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Connect to DuckDB\n",
    "db_path = Path('../data/nyc_mobility.duckdb')\n",
    "conn = duckdb.connect(str(db_path), read_only=True)\n",
    "\n",
    "print(f\"Connected to DuckDB at: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Yellow Taxi Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Null Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get null counts for all columns\n",
    "yellow_nulls = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_rows,\n",
    "        SUM(CASE WHEN tpep_pickup_datetime IS NULL THEN 1 ELSE 0 END) as null_pickup_time,\n",
    "        SUM(CASE WHEN tpep_dropoff_datetime IS NULL THEN 1 ELSE 0 END) as null_dropoff_time,\n",
    "        SUM(CASE WHEN passenger_count IS NULL THEN 1 ELSE 0 END) as null_passenger_count,\n",
    "        SUM(CASE WHEN trip_distance IS NULL THEN 1 ELSE 0 END) as null_trip_distance,\n",
    "        SUM(CASE WHEN fare_amount IS NULL THEN 1 ELSE 0 END) as null_fare_amount,\n",
    "        SUM(CASE WHEN total_amount IS NULL THEN 1 ELSE 0 END) as null_total_amount,\n",
    "        SUM(CASE WHEN payment_type IS NULL THEN 1 ELSE 0 END) as null_payment_type\n",
    "    FROM raw_data.yellow_taxi\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Yellow Taxi - Null Value Counts:\")\n",
    "display(yellow_nulls)\n",
    "\n",
    "# Calculate null percentages\n",
    "total_rows = yellow_nulls['total_rows'][0]\n",
    "null_cols = [col for col in yellow_nulls.columns if col.startswith('null_')]\n",
    "null_pcts = {col.replace('null_', ''): (yellow_nulls[col][0] / total_rows * 100) \n",
    "             for col in null_cols}\n",
    "\n",
    "# Plot null percentages\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(null_pcts.keys(), null_pcts.values())\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Null Percentage (%)')\n",
    "plt.title('Yellow Taxi - Null Value Percentages')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution statistics for key numeric columns\n",
    "yellow_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        MIN(trip_distance) as min_distance,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY trip_distance) as q1_distance,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY trip_distance) as median_distance,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY trip_distance) as q3_distance,\n",
    "        MAX(trip_distance) as max_distance,\n",
    "        MIN(total_amount) as min_fare,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY total_amount) as q1_fare,\n",
    "        PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY total_amount) as median_fare,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY total_amount) as q3_fare,\n",
    "        MAX(total_amount) as max_fare,\n",
    "        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY trip_distance) as p95_distance,\n",
    "        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY total_amount) as p95_fare\n",
    "    FROM raw_data.yellow_taxi\n",
    "    WHERE trip_distance >= 0 AND total_amount >= 0\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Yellow Taxi - Distribution Statistics:\")\n",
    "display(yellow_stats)\n",
    "\n",
    "# Identify potential outliers (values beyond 95th percentile)\n",
    "p95_distance = yellow_stats['p95_distance'][0]\n",
    "p95_fare = yellow_stats['p95_fare'][0]\n",
    "\n",
    "outliers = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_trips,\n",
    "        SUM(CASE WHEN trip_distance > {p95_distance} THEN 1 ELSE 0 END) as outlier_distance,\n",
    "        SUM(CASE WHEN total_amount > {p95_fare} THEN 1 ELSE 0 END) as outlier_fare,\n",
    "        SUM(CASE WHEN trip_distance <= 0 THEN 1 ELSE 0 END) as zero_distance,\n",
    "        SUM(CASE WHEN total_amount <= 0 THEN 1 ELSE 0 END) as zero_fare\n",
    "    FROM raw_data.yellow_taxi\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nYellow Taxi - Outlier Counts:\")\n",
    "display(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions (capped at 95th percentile for clarity)\n",
    "yellow_sample = conn.execute(f\"\"\"\n",
    "    SELECT trip_distance, total_amount\n",
    "    FROM raw_data.yellow_taxi\n",
    "    WHERE trip_distance > 0 AND trip_distance <= {p95_distance}\n",
    "      AND total_amount > 0 AND total_amount <= {p95_fare}\n",
    "    LIMIT 10000\n",
    "\"\"\").df()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(yellow_sample['trip_distance'], bins=50, edgecolor='black')\n",
    "axes[0].set_xlabel('Trip Distance (miles)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Yellow Taxi - Trip Distance Distribution (≤95th percentile)')\n",
    "\n",
    "axes[1].hist(yellow_sample['total_amount'], bins=50, edgecolor='black')\n",
    "axes[1].set_xlabel('Total Amount ($)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Yellow Taxi - Fare Distribution (≤95th percentile)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Temporal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trips by hour of day\n",
    "yellow_hourly = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(HOUR FROM tpep_pickup_datetime) as hour,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.yellow_taxi\n",
    "    GROUP BY hour\n",
    "    ORDER BY hour\n",
    "\"\"\").df()\n",
    "\n",
    "# Trips by day of week\n",
    "yellow_daily = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        DAYNAME(tpep_pickup_datetime) as day_name,\n",
    "        DAYOFWEEK(tpep_pickup_datetime) as day_num,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.yellow_taxi\n",
    "    GROUP BY day_name, day_num\n",
    "    ORDER BY day_num\n",
    "\"\"\").df()\n",
    "\n",
    "# Plot temporal distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(yellow_hourly['hour'], yellow_hourly['trip_count'], marker='o')\n",
    "axes[0].set_xlabel('Hour of Day')\n",
    "axes[0].set_ylabel('Trip Count')\n",
    "axes[0].set_title('Yellow Taxi - Trips by Hour of Day')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(yellow_daily['day_name'], yellow_daily['trip_count'])\n",
    "axes[1].set_xlabel('Day of Week')\n",
    "axes[1].set_ylabel('Trip Count')\n",
    "axes[1].set_title('Yellow Taxi - Trips by Day of Week')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Geographic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top pickup locations\n",
    "try:\n",
    "    yellow_pickup_locs = conn.execute(\"\"\"\n",
    "        SELECT \n",
    "            PULocationID as location_id,\n",
    "            COUNT(*) as pickup_count\n",
    "        FROM raw_data.yellow_taxi\n",
    "        WHERE PULocationID IS NOT NULL\n",
    "        GROUP BY location_id\n",
    "        ORDER BY pickup_count DESC\n",
    "        LIMIT 15\n",
    "    \"\"\").df()\n",
    "    \n",
    "    print(\"Top 15 Pickup Locations:\")\n",
    "    display(yellow_pickup_locs)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(yellow_pickup_locs['location_id'].astype(str), \n",
    "            yellow_pickup_locs['pickup_count'])\n",
    "    plt.xlabel('Location ID')\n",
    "    plt.ylabel('Pickup Count')\n",
    "    plt.title('Yellow Taxi - Top 15 Pickup Locations')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not analyze pickup locations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FHV Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Null Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get null counts for key columns\n",
    "fhv_nulls = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_rows,\n",
    "        SUM(CASE WHEN pickup_datetime IS NULL THEN 1 ELSE 0 END) as null_pickup_time,\n",
    "        SUM(CASE WHEN dropOff_datetime IS NULL THEN 1 ELSE 0 END) as null_dropoff_time,\n",
    "        SUM(CASE WHEN PUlocationID IS NULL THEN 1 ELSE 0 END) as null_pu_location,\n",
    "        SUM(CASE WHEN DOlocationID IS NULL THEN 1 ELSE 0 END) as null_do_location\n",
    "    FROM raw_data.fhv_taxi\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"FHV - Null Value Counts:\")\n",
    "display(fhv_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Temporal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trips by hour of day\n",
    "fhv_hourly = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(HOUR FROM pickup_datetime) as hour,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.fhv_taxi\n",
    "    GROUP BY hour\n",
    "    ORDER BY hour\n",
    "\"\"\").df()\n",
    "\n",
    "# Trips by day of week\n",
    "fhv_daily = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        DAYNAME(pickup_datetime) as day_name,\n",
    "        DAYOFWEEK(pickup_datetime) as day_num,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.fhv_taxi\n",
    "    GROUP BY day_name, day_num\n",
    "    ORDER BY day_num\n",
    "\"\"\").df()\n",
    "\n",
    "# Plot temporal distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(fhv_hourly['hour'], fhv_hourly['trip_count'], marker='o', color='orange')\n",
    "axes[0].set_xlabel('Hour of Day')\n",
    "axes[0].set_ylabel('Trip Count')\n",
    "axes[0].set_title('FHV - Trips by Hour of Day')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(fhv_daily['day_name'], fhv_daily['trip_count'], color='orange')\n",
    "axes[1].set_xlabel('Day of Week')\n",
    "axes[1].set_ylabel('Trip Count')\n",
    "axes[1].set_title('FHV - Trips by Day of Week')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CitiBike Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Schema Detection and Null Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect date column name (varies by year)\n",
    "citibike_cols = conn.execute(\"\"\"\n",
    "    SELECT column_name \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'raw_data' AND table_name = 'trips'\n",
    "\"\"\").df()\n",
    "\n",
    "# Common date column names\n",
    "if 'started_at' in citibike_cols['column_name'].values:\n",
    "    date_col = 'started_at'\n",
    "elif 'starttime' in citibike_cols['column_name'].values:\n",
    "    date_col = 'starttime'\n",
    "else:\n",
    "    date_col = citibike_cols['column_name'][0]  # Fallback\n",
    "\n",
    "print(f\"Using date column: {date_col}\")\n",
    "print(f\"\\nAll columns in CitiBike table:\")\n",
    "print(citibike_cols['column_name'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Temporal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trips by hour of day\n",
    "citibike_hourly = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(HOUR FROM {date_col}) as hour,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.trips\n",
    "    GROUP BY hour\n",
    "    ORDER BY hour\n",
    "\"\"\").df()\n",
    "\n",
    "# Trips by day of week\n",
    "citibike_daily = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        DAYNAME({date_col}) as day_name,\n",
    "        DAYOFWEEK({date_col}) as day_num,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM raw_data.trips\n",
    "    GROUP BY day_name, day_num\n",
    "    ORDER BY day_num\n",
    "\"\"\").df()\n",
    "\n",
    "# Plot temporal distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(citibike_hourly['hour'], citibike_hourly['trip_count'], \n",
    "            marker='o', color='green')\n",
    "axes[0].set_xlabel('Hour of Day')\n",
    "axes[0].set_ylabel('Trip Count')\n",
    "axes[0].set_title('CitiBike - Trips by Hour of Day')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(citibike_daily['day_name'], citibike_daily['trip_count'], color='green')\n",
    "axes[1].set_xlabel('Day of Week')\n",
    "axes[1].set_ylabel('Trip Count')\n",
    "axes[1].set_title('CitiBike - Trips by Day of Week')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weather Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Null Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get null counts for key weather columns\n",
    "weather_nulls = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_rows,\n",
    "        SUM(CASE WHEN timestamp IS NULL THEN 1 ELSE 0 END) as null_timestamp,\n",
    "        SUM(CASE WHEN temp IS NULL THEN 1 ELSE 0 END) as null_temp,\n",
    "        SUM(CASE WHEN humidity IS NULL THEN 1 ELSE 0 END) as null_humidity,\n",
    "        SUM(CASE WHEN wind_speed IS NULL THEN 1 ELSE 0 END) as null_wind_speed,\n",
    "        SUM(CASE WHEN weather_main IS NULL THEN 1 ELSE 0 END) as null_weather_main\n",
    "    FROM raw_data.hourly_weather\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Weather - Null Value Counts:\")\n",
    "display(weather_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Weather Conditions Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather condition frequency\n",
    "weather_conditions = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        weather_main,\n",
    "        COUNT(*) as hour_count,\n",
    "        ROUND(AVG(temp), 2) as avg_temp,\n",
    "        ROUND(AVG(humidity), 2) as avg_humidity\n",
    "    FROM raw_data.hourly_weather\n",
    "    WHERE weather_main IS NOT NULL\n",
    "    GROUP BY weather_main\n",
    "    ORDER BY hour_count DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Weather Conditions Distribution:\")\n",
    "display(weather_conditions)\n",
    "\n",
    "# Plot weather conditions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(weather_conditions['weather_main'], weather_conditions['hour_count'])\n",
    "plt.xlabel('Weather Condition')\n",
    "plt.ylabel('Hours')\n",
    "plt.title('Weather Conditions Distribution (Q4 2023)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Temperature and Humidity Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily temperature and humidity averages\n",
    "weather_daily = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        DATE(timestamp) as date,\n",
    "        AVG(temp) as avg_temp,\n",
    "        MIN(temp) as min_temp,\n",
    "        MAX(temp) as max_temp,\n",
    "        AVG(humidity) as avg_humidity\n",
    "    FROM raw_data.hourly_weather\n",
    "    GROUP BY date\n",
    "    ORDER BY date\n",
    "\"\"\").df()\n",
    "\n",
    "# Plot temperature trends\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "axes[0].plot(weather_daily['date'], weather_daily['avg_temp'], label='Avg Temp', linewidth=2)\n",
    "axes[0].fill_between(weather_daily['date'], \n",
    "                      weather_daily['min_temp'], \n",
    "                      weather_daily['max_temp'], \n",
    "                      alpha=0.3, label='Min-Max Range')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Temperature (°C)')\n",
    "axes[0].set_title('Daily Temperature Trends (Q4 2023)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(weather_daily['date'], weather_daily['avg_humidity'], \n",
    "            color='green', linewidth=2)\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Humidity (%)')\n",
    "axes[1].set_title('Daily Humidity Trends (Q4 2023)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Completeness Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA QUALITY ASSESSMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Yellow Taxi:\")\n",
    "print(f\"   - Data completeness: Good\")\n",
    "print(f\"   - Temporal patterns: Clear peak hours visible\")\n",
    "print(f\"   - Outliers: Present but within expected range\")\n",
    "\n",
    "print(\"\\n2. FHV:\")\n",
    "print(f\"   - Data completeness: Good\")\n",
    "print(f\"   - Temporal patterns: Different from yellow taxi (more evening rides)\")\n",
    "\n",
    "print(\"\\n3. CitiBike:\")\n",
    "print(f\"   - Data completeness: Good\")\n",
    "print(f\"   - Temporal patterns: Strong commute peaks\")\n",
    "\n",
    "print(\"\\n4. Weather:\")\n",
    "print(f\"   - Data completeness: Excellent (hourly data)\")\n",
    "print(f\"   - Seasonal trends: Clear Q4 cooling pattern\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Next Steps:\")\n",
    "print(\"  - Data quality is sufficient for analysis\")\n",
    "print(\"  - Proceed to exploratory analysis (03_exploratory_analysis.ipynb)\")\n",
    "print(\"  - Consider filtering extreme outliers for specific analyses\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()\n",
    "print(\"\\nConnection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
